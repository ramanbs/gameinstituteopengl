Steps for drawing triangle in OpenGL

1. Create a buffer in GPU memory for the mesh
2. Fill the buffer with mesh data (vertices) - vertex has some attributes, e.g. : position, color, texture coordinate etc
3. Create shaders for knowing (GPU) how to draw your mesh
4. Define vertex format for the mesh vertices 
5. Draw the mesh
   a) Set the shader as current.
   b) Set the buffer as current
   c) Draw the buffer


Stages for pipeline : 

Stage 							|					Input				| Output

1. Vertex Shader (Programmable)			|		Raw Vertices (From CPU) | Transformed Vertices  
2. Primitive Assembly & Rasterizer		|		Transformed Vertices	| Fragments
3. Fragment Shader(Programmable)		| 		Fragments				| Processed Fragments
4. Tests & Blending						| 		Processed Fragments		| Pixels


Vertex Shader : Changes the 3d coordinates into a different 3d coordinate space (normalized device coordinates)
Rasterization : takes primitive and coverts them into blocks of fragment for the fragment shader to assign color to them

the triangle coordinates we are gonna draw is : (-0.5, -0.5), (0.5, -0.5), (0, 0.5) considering the 
boundaries to be : (0, 1), (-1, 0), (1, 0) and (0, -1)
center would be : (0, 0)
z component - 0
Coordinate Space used above is the one  given out by the vertex shader

Vertex Buffer Object - OpenGL Object - generic place in memeory to hold data, so wen sedn the array of vertices to this buffer in GPU, so as to minimize the traffic of sending the data from CPU to GPU

//GL_STATIC_DRAW - create once, setup once use it a lot, GL_DYNAMIC_DRAW - create once, change a lot and use it a lot, GL_STREAM_DRAW - create once, setup once and use once
	glBufferData(GL_ARRAY_BUFFER, sizeof(vertices), vertices, GL_STATIC_DRAW); 

For core openGL we need to create VertexArrayObject - holds info for our buffer so that when we draw we need not refer buffer object but VAO instead. MOst meshes object holds a collections of one or more VBO which holds vertext point, vertex normal, texture coords. Older OpenGL needs to bind each data buffer and define memory layout every time you need to draw. VAO collects various info like pointer to VBO and only VAO can be binded and used before we draw something instead of providing everything every time we need to draw something (old way of doing it)

Steps for creating shader : 

1. Create vertex shader.
2. Create fragment shader.
3. Compile the shaders.
4. Create a shader program.
5. Attach the shaders to the program.
6. Link the compiled shaders into a single Program.
7. Use the program.

Indexed Buffer vs Normal Vertex Buffer : 

1. Index Buffer provides the index of the vertex to be drawn ( just like in Unity we provide vertices array and an index array)
2. Index Buffer prevents re-draw of vertices.

GLSL Shader Data types

Scalar : 
float, double, int, uint and bool

Vectors : 
vec2, vec3, vec4
ivec2, ivec3, .. for all scalar corresponding types

Square Matrices: 

mat2, mat3, mat4,
dmat2, dmat3, dmat4

Non Square matrices : 
mat{2x3, 4}x{2,3,4}
dmat{2x3, 4}x{2,3,4}

Uniform variables are available to the shaders through the CPU and they are global to all the shaders in the program. 
Value of uniform remains constant for a draw call, unline vertex and fragment where they change for each vertext or fragment.

For textures we need to load images into our application not supported directly by opengl. We are using a third party lib called "stb" by "nothings/stb" in github.
We need only stb_image.h out of this lib.
 There are other libs called soil, image magic, freeimage
 
Image coordinate system is different from normalized opengl coordinate system.

The origin (0,0) for image coordinate is in top left corner whereas in opengl it is bottom left corner.

Pixels are to image what texels are to texture in opengl. Since texels are pixels normalized in opengl coordinate space between 0 and 1 .

Texture wrapping mode decides what happens when texture u,v coordinates are outside the (0,0) to (1,1) range.
Wrapping modes available : 

1. GL_REPEAT (default)
So fragment shader is sampling the texture and it finds u,v more than 1 then it sets back to initial value of texture coordinate and starts from beginning again
2. GL_MIRRORED_REPEAT
Similar to GL_REPEAT but starts from end after sampling once 

3. GL_CLAMP_TO_EDGE
After sampling the texture once it will repeat the last color in both row and column.

4. GL_CLAMP_TO_BORDER
Similar to clamp to edge but, repeats the color we specify at the end of sampling the texture. Default color is black.

Texture filtering : 
If the area where we map the texture to is same as the texture size, then we would not need filtering but thats such a rare case.

2 Mappings : 1. Magnification 2. Minification

GL_NEAREST : Nearest neighbor filtering. In this for the current texel being sampled, the texel closest to the fragment that is sampling the texel will be returned. (jagged and pixelated)


GL_LINEAR or billinear : In this the wieghted average color of the neighboring texels (2- in 1D, 4 in 2D and 8 in 3D) is returned (neighbors of the current texel being sampled) to the fragment that is sampling the texel. 
GL_LINEAR or billinear : In this the wieghted average color of the neighboring texels is returned (neighbors of the current texel being sampled) to the fragment that is sampling the texel.  (smoothed out)


MipMaps :

Multiple images within texture file, each 1/4 the size of the previous image, might go upto size of a pixel. This gives a boost in performance in terms of LOD. So when this  texture is shown mapped to an object far away, it doesnt have to rendering the full blown high resolution image instead it will use one of the lower resolution one depending on required LOD.  

In fragment shaders, the texture sampler are there in built provided by GLSL. There are many types and we have to find about them. The one that is used in case of importing airplane.png is sampler2D.

So when the texture loaded, it loaded flipped. There are ways to rectify this :

1. by image loader itself but stb image laoder might not do this for use
2. by flipping the y coordinate in shader 
3. way taught in tutorial

Multi-texturing :
Lay multiple textures on the same area. Like normal, diffuse and other maps on the same area. 

Coordinate Systems : 

Upto now we have been drawing in normalized device coordinate system.

There are 5 coordinate systems in OpenGL: 

1. Object Space(Local) : This is basically a 3-d objects coordinate space, in which it was made, wherein there is an origin specified within the model and serves as a point of reference or relative for rest of vertices.

2. World Space : This is the space our model will live in. Hence the position of model in the world is relative to this. 

3. Camera coordinate system (View Space) : Camera Space, so everything in teh world is relative to camera position as if camera is origin
In 3d graphics, camera never moves, everything else moves in respect to the camera, since the view is like that.

Right vs Left Coordinate System. 
OPengl is Right Handed and DirectX is left handed. In right handed the z-axis ponts towards the camera whereas in left it is away from the camera.

Matrix Multiplication Order : 
Suppose if we want to translate our model in 3d space by (0,15,-15) and then rotate by 90 degrees.

M = T * R (Matrix Multiplication Order - righ to left) - so this will rotate this model by 90 degrees and then translate it to position. 

4. Clip Space : From the view Space we create the projection matrix to generate our clip space. Takes in the 3d coordiantes and projects into the 2d space. Two Types : 

1. Orthogographics : Every vertex  is directly mapped to clip space, has same depth for very vertex. The view frustrum for an orthigraphic projection is a cube.

2. Perspective : Gives depth Things away from camera gets smaller. View frustrum is a pyramid with top cut off.

Multiply one of these projection matrices and we get our model in clip space.



Pipeline of Coordinate Space Transformation : 

1.Local Space ---Model Matrix---> 2. World Space ---View Matrix---> 3. View Space ---Projection Matrix ---> 4. Clip Space ---Perspective divided by W---> 5. Normalized Device Space ---Viewport Transform---> Viewport or Screen Space

Transforming a Vertex across all these coordinate spaces mathematically : 

Vertex in Clip Space[4X1] = Projection Matrix[4X4] X View Space [4X4] X World Space[4X4] X Model Space [4X4] X Vertex in Local Space [4X1]  
<--------------------------------------------- Order Of Multiply for Column Major Matrices


View Matrix : 

glm::viewMatrix (glm::lookup) =   rotate                             translate
				  -                                -        -                -
				 |  rightx , righty, rightz, 0      |      | 1,  0,   0, -Px  |
				 |  upx,     upy,    upz,   0       |   *  | 0,  1,   0, -Py  |
				 |  forwardx, forwardy, forwardz, 0 |      | 0,  0,   1, -Pz  |
				 |  0,       0,       0,     1,     |      | 0,  0,   0,  1   |
				 |_								   _|      |_                _|
				 
Virtual Camera's Right, Up and Forward unit direction vectors
P  = Virtual Camera ("eye") position vector in the world ( negative because we really move the world  in the opp direction of the camera)



-------------------------
Virtual Camera Notes : Without the depth buffer bit enabled, the cube looks weird rotating, so basically without the depth buffer enables the cube looks like the described view frustrum without the video being able to perceive the depth of pixels, hence the vertex are filled as such as the view frustrum.

Orbit Camera : 
updateCameraVectors() 

For making a floor : We take the same cube and squish and stretch it with a different texture to make a floor out of it.

Meshes : 

Wavefront .obj model file 

Simpilified OBJ file format 

1. #vertices (v) - x,y and z coordinates
2. #texture coordinates (vt) - u, v and w coordinates (0-1 range)
3. #normals (vn) - direction vectors for each vertex and point in the direction perpendicular to the face
4. usemtl robot_body_material - not gonna use this 
5. #faces - three or more sets of data - each face has three vertices we assumes and indices are mentioned for the properties that make up a face. e.g. 
#faces
f    6/1/1   7/2/2    3/3/3
--   v/vt/vn v/vt/vn  v/vt/vn

Other commands in obj file not covered : 
g -  group
o - objects or groups of groups
s - smoothing group


				 



 

